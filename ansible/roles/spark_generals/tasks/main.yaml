- name: Update
  apt:
    update_cache: yes
    upgrade: yes

- name: Install sudo, unzip, curl, vim and git
  package:
    name: "{{ item }}"
    state: present
  loop:
    - unzip
    - curl
    - wget
    - net-tools
    - git
    - vim
    - tree
    - lsof
    - netcat-traditional
    - telnet
    - iptables
    - iptables-persistent
    - default-jdk
    - scala

- name: Create an iptable config file
  ansible.builtin.template:
    src: iptables.rules
    dest: "/etc/iptables.rules"
    # mode: "0755"

- name: Get current VM subnet
  shell: |
    private_ip=$(hostname -I | awk '{print $1}')

    if [ -n "`echo $private_ip | grep -e '10.0.2'`" ]; then 
      echo "2"
    else
      echo "3"
    fi
  args: 
    executable:
      /bin/bash
  register: subnet

- name: Change the subnet in the iptable config file
  ansible.builtin.lineinfile:
    path: "/etc/iptables.rules"
    regexp: '^-4 -A INPUT -s 10.0.CHANGE.0/24 ! -i lo -j ACCEPT'
    line: "-4 -A INPUT -s 10.0.{{ subnet.stdout }}.0/24 ! -i lo -j ACCEPT"
    backrefs: yes
  
- name: Apply the iptables rules
  ansible.builtin.shell: "iptables-restore < /etc/iptables.rules"

- name: Install prerequisites
  apt:
    name: "{{ item }}"
    state: present
  loop:
    - software-properties-common
    - python3-pip
    - python3-dev
    - build-essential
    - libssl-dev
    - libffi-dev
    - python3-setuptools

- name: Install Python
  apt:
    name: python3.11
    state: present
    update_cache: yes

- name: Download Spark
  get_url:
    url: "https://archive.apache.org/dist/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz"
    dest: "/home/{{ user }}/spark-3.2.0-bin-hadoop3.5.3.tgz"

- name: Create a spark folder
  ansible.builtin.file:
    path: "/home/{{ user }}/spark"
    state: directory

- name: Install Spark
  unarchive:
    src: "/home/{{ user }}/spark-3.2.0-bin-hadoop3.5.3.tgz"
    dest: "/home/{{ user }}/spark/"
    remote_src: yes

- name: setup bashrc file
  command: |
    echo "export SPARK_HOME=/home/admin/spark/spark-3.5.3-bin-hadoop3" >> /home/{{ user }}/.bashrc
    echo "export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin" >> /home/{{ user }}/.bashrc

# - name: Remove spark tar
#   command: "rm -rf /home/{{ user }}/spark-3.2.0-bin-hadoop3.5.3.tgz"

# - name: Remove spark folder
#   command: "rm -rf /home/{{ user }}/spark"